{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_stats(dataset_dir):\n",
    "    sum_r = sum_g = sum_b = 0.0\n",
    "    sum_sq_r = sum_sq_g = sum_sq_b = 0.0\n",
    "    total_pixels = 0\n",
    "    processed_files = 0\n",
    "    problematic_files = []\n",
    "\n",
    "    total_images = 0\n",
    "    for class_dir in os.listdir(dataset_dir):\n",
    "        class_path = os.path.join(dataset_dir, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            total_images += len([f for f in os.listdir(class_path) \n",
    "                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "    with tqdm(total=total_images, desc=\"Processing Images\", \n",
    "             unit=\"img\", dynamic_ncols=True) as pbar:\n",
    "        \n",
    "        for class_dir in os.listdir(dataset_dir):\n",
    "            class_path = os.path.join(dataset_dir, class_dir)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "\n",
    "            for img_name in os.listdir(class_path):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                \n",
    "                if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    problematic_files.append(f\"{img_path} - Not an image\")\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        raise ValueError(\"OpenCV failed to read image\")\n",
    "                        \n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    if img.dtype != np.uint8:\n",
    "                        raise ValueError(f\"Unexpected dtype: {img.dtype}\")\n",
    "                        \n",
    "                    img = img.astype(np.float32) / 255.0\n",
    "                    \n",
    "                    sum_r += np.sum(img[:, :, 0])\n",
    "                    sum_g += np.sum(img[:, :, 1])\n",
    "                    sum_b += np.sum(img[:, :, 2])\n",
    "                    \n",
    "                    sum_sq_r += np.sum(np.square(img[:, :, 0]))\n",
    "                    sum_sq_g += np.sum(np.square(img[:, :, 1]))\n",
    "                    sum_sq_b += np.sum(np.square(img[:, :, 2]))\n",
    "                    \n",
    "                    total_pixels += img.shape[0] * img.shape[1]\n",
    "                    processed_files += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    problematic_files.append(f\"{img_path} - {str(e)}\")\n",
    "                \n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix({\n",
    "                        'Processed': processed_files,\n",
    "                        'Errors': len(problematic_files),\n",
    "                        'Current': os.path.basename(class_dir)\n",
    "                    })\n",
    "\n",
    "    if total_pixels == 0:\n",
    "        raise ValueError(\"No valid images processed - check dataset path or file formats\")\n",
    "\n",
    "    mean = [\n",
    "        round(sum_r / total_pixels, 5),\n",
    "        round(sum_g / total_pixels, 5),\n",
    "        round(sum_b / total_pixels, 5)\n",
    "    ]\n",
    "    \n",
    "    std = [\n",
    "        round(np.sqrt((sum_sq_r / total_pixels) - (mean[0] ** 2)), 5),\n",
    "        round(np.sqrt((sum_sq_g / total_pixels) - (mean[1] ** 2)), 5),\n",
    "        round(np.sqrt((sum_sq_b / total_pixels) - (mean[2] ** 2)), 5)\n",
    "    ]\n",
    "\n",
    "    print(\"\\nValidation Summary:\")\n",
    "    print(f\"Total images attempted: {total_images}\")\n",
    "    print(f\"Successfully processed: {processed_files}\")\n",
    "    print(f\"Problematic files: {len(problematic_files)}\")\n",
    "    \n",
    "    if problematic_files:\n",
    "        print(\"\\nFirst 5 errors:\")\n",
    "        for error in problematic_files[:5]:\n",
    "            print(f\" - {error}\")\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_dataset = r'Dataset/All'\n",
    "mean, std = calculate_dataset_stats(root_dir_dataset)\n",
    "\n",
    "dataset_mean = [round(float(m), 5) for m in mean]\n",
    "dataset_std = [round(float(s), 5) for s in std]\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "print(\"Dataset Mean (RGB):\", dataset_mean)\n",
    "print(\"Dataset Std (RGB):\", dataset_std)\n",
    "\n",
    "assert all(0 <= m <= 1 for m in dataset_mean), \"Mean values out of [0,1] range\"\n",
    "assert all(0 <= s <= 1 for s in dataset_std), \"Std values out of [0,1] range\"\n",
    "\n",
    "if (abs(mean[0]*255 - 0.485 * 255) < 0.01):\n",
    "    print(\"Red mean mismatch\")\n",
    "if (abs(mean[1]*255 - 0.456 * 255) < 0.01):\n",
    "    print(\"Green mean mismatch\")\n",
    "if (abs(mean[2]*255 - 0.406 * 255) < 0.01):\n",
    "    print(\"Blue mean mismatch\")\n",
    "\n",
    "if (abs(std[0]*255 - 0.229 * 255) < 0.01):\n",
    "    print(\"Red std mismatch\")\n",
    "if (abs(std[1]*255 - 0.224 * 255) < 0.01):\n",
    "    print(\"Green std mismatch\")\n",
    "if (abs(std[2]*255 - 0.225 * 255) < 0.01):\n",
    "    print(\"Blue std mismatch\")\n",
    "\n",
    "print(\"\\nBasic validation checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_analysis(image_path):\n",
    "    analysis = {}\n",
    "    \n",
    "    analysis['path'] = image_path\n",
    "    analysis['filesize'] = os.path.getsize(image_path)\n",
    "    analysis['modified_time'] = os.path.getmtime(image_path)\n",
    "    \n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            analysis['format'] = img.format\n",
    "            analysis['mode'] = img.mode\n",
    "            analysis['size'] = img.size\n",
    "            analysis['info'] = img.info\n",
    "            \n",
    "        img_cv = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img_cv is not None:\n",
    "            analysis['dtype'] = img_cv.dtype\n",
    "            analysis['shape'] = img_cv.shape\n",
    "            analysis['channels'] = img_cv.shape[2] if len(img_cv.shape) > 2 else 1\n",
    "            \n",
    "            analysis['stats'] = {\n",
    "                'min': img_cv.min(),\n",
    "                'max': img_cv.max(),\n",
    "                'mean': img_cv.mean(),\n",
    "                'std': img_cv.std(),\n",
    "                'unique': len(np.unique(img_cv))\n",
    "            }\n",
    "            \n",
    "            import hashlib\n",
    "            analysis['md5'] = hashlib.md5(img_cv.tobytes()).hexdigest()\n",
    "            \n",
    "            analysis['has_alpha'] = (img_cv.shape[2] == 4) if len(img_cv.shape) > 2 else False\n",
    "            \n",
    "        return analysis\n",
    "    except Exception as e:\n",
    "        analysis['error'] = str(e)\n",
    "        return analysis\n",
    "\n",
    "def visualize_image(analysis):\n",
    "    img = cv2.imread(analysis['path'])\n",
    "    if img is None:\n",
    "        return\n",
    "\n",
    "    display_text = [\n",
    "        f\"Size: {analysis['size'][0]}x{analysis['size'][1]}\",\n",
    "        f\"Channels: {analysis['channels']}\",\n",
    "        f\"Mode: {analysis['mode']}\",\n",
    "        f\"Type: {analysis['dtype']}\",\n",
    "        f\"Range: {analysis['stats']['min']}-{analysis['stats']['max']}\",\n",
    "        f\"Mean: {analysis['stats']['mean']:.1f} Â± {analysis['stats']['std']:.1f}\"\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    plt.text(0.5, -0.1, '\\n'.join(display_text),\n",
    "             transform=plt.gca().transAxes,\n",
    "             verticalalignment='top',\n",
    "             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_dataset(dataset_root, sample_per_folder=1, save_report=False):\n",
    "    report = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(dataset_root):\n",
    "        if not files:\n",
    "            continue\n",
    "            \n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        samples = image_files[:sample_per_folder]\n",
    "        \n",
    "        for img_file in samples:\n",
    "            img_path = os.path.join(root, img_file)\n",
    "            analysis = get_image_analysis(img_path)\n",
    "            report.append(analysis)\n",
    "            \n",
    "\n",
    "            print(f\"\\nClass: {os.path.basename(root)}\")\n",
    "            print(f\"Image: {img_file}\")\n",
    "            print(\"-\"*40)\n",
    "            for k, v in analysis.items():\n",
    "                if k == 'exif': continue\n",
    "                if k == 'info': continue\n",
    "                print(f\"{k:>15}: {v}\")\n",
    "                \n",
    "            if 'error' not in analysis:\n",
    "                visualize_image(analysis)\n",
    "            else:\n",
    "                print(f\"Error processing image: {analysis['error']}\")\n",
    "    \n",
    "    if save_report:\n",
    "        with open('dataset_analysis_report.txt', 'w') as f:\n",
    "            for entry in report:\n",
    "                f.write(f\"{'-'*40}\\n\")\n",
    "                for k, v in entry.items():\n",
    "                    f.write(f\"{k:>15}: {v}\\n\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "\n",
    "dataset_path = r\"Dataset/All\"\n",
    "analyze_dataset(dataset_path, sample_per_folder=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'Dataset'\n",
    "root_dir_train = r'Dataset/Train'\n",
    "root_dir_test = r'Dataset/Test'\n",
    "root_dir_val = r'Dataset/Val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahaa\\AppData\\Local\\Temp\\ipykernel_20752\\2973037813.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = [plt.cm.get_cmap('viridis')(i / n_classes) for i in range(n_classes)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_folders = os.listdir(root_dir_train)\n",
    "\n",
    "image_counts = {}\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    path = os.path.join(root_dir_train, class_folder)\n",
    "    if os.path.isdir(path):\n",
    "        image_count = len(os.listdir(path))\n",
    "        image_counts[class_folder] = image_count\n",
    "\n",
    "# Convert dictionary keys to list for matplotlib\n",
    "class_names = list(image_counts.keys())\n",
    "count_values = list(image_counts.values())\n",
    "\n",
    "n_classes = len(class_names)\n",
    "colors = [plt.cm.get_cmap('viridis')(i / n_classes) for i in range(n_classes)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(class_names, count_values, color=colors)\n",
    "plt.xlabel('Class Name')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Class (Train)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_train = r'Dataset/train'\n",
    "root_dir_augmented = r'Dataset/Augmented'\n",
    "os.makedirs(root_dir_augmented, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define your Albumentations transform (similar to ImageDataGenerator settings)\n",
    "# Note: For saving images, we do not apply normalization so that pixel values remain in [0,255].\n",
    "augment_transform = A.Compose([\n",
    "    A.Resize(128, 128),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=0, p=0.5),\n",
    "    A.Affine(shear=15, p=0.5),\n",
    "    A.Zoom(scale_limit=0.15, p=0.5),\n",
    "    # You may add more transformations if desired.\n",
    "    # ToTensorV2() is omitted here since we want to save as images.\n",
    "])\n",
    "\n",
    "# Loop through each class folder in train_path\n",
    "class_folders = sorted([d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))])\n",
    "image_counts = {}\n",
    "\n",
    "for class_folder in class_folders:\n",
    "    class_dir = os.path.join(train_path, class_folder)\n",
    "    \n",
    "    # Count number of images in this class\n",
    "    images = sorted(glob.glob(os.path.join(class_dir, \"*.png\")))\n",
    "    image_counts[class_folder] = len(images)\n",
    "    \n",
    "    # Create corresponding output folder (preserve class structure)\n",
    "    output_class_dir = os.path.join(output_aug_dir, class_folder)\n",
    "    os.makedirs(output_class_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each image; create one augmented version per image, for example.\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Skipping unreadable file: {img_path}\")\n",
    "            continue\n",
    "        # Apply augmentation transform\n",
    "        augmented = augment_transform(image=img)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        # Save augmented image. You may name it based on original filename.\n",
    "        save_name = \"aug_\" + img_name\n",
    "        save_path = os.path.join(output_class_dir, save_name)\n",
    "        cv2.imwrite(save_path, aug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mean = [0.48948, 0.48214, 0.53307]\n",
    "dataset_std = [0.21354, 0.2212, 0.20459]\n",
    "\n",
    "img_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_album = A.Compose([\n",
    "        A.Resize(128, 128),\n",
    "        A.Affine(\n",
    "            scale=(0.95, 1.05),\n",
    "            shear=(-5, 5),\n",
    "            fill=0,\n",
    "            p=0.7),\n",
    "        A.Perspective(\n",
    "            scale=(0.05, 0.1),\n",
    "            keep_size=True,\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            fill=0,\n",
    "            p=0.5),\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=(-0.5, 0.5),\n",
    "            contrast_limit=(-0.2, 0.2),\n",
    "            p=0.8),\n",
    "        A.RGBShift(\n",
    "            r_shift_limit=(-10, 10),\n",
    "            g_shift_limit=(-10, 10),\n",
    "            b_shift_limit=(-10, 10),\n",
    "            p=0.8),\n",
    "        A.MotionBlur(\n",
    "            blur_limit=(5, 7),\n",
    "            p=0.3),\n",
    "        A.GaussNoise(\n",
    "            std_range=(0.01, 0.02),\n",
    "            p=0.3),\n",
    "        A.Normalize(\n",
    "            mean=tuple(dataset_mean),\n",
    "            std=tuple(dataset_std),\n",
    "            max_pixel_value=255.0,\n",
    "            normalization=\"standard\",\n",
    "            p=1.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_simple = A.Compose([\n",
    "        A.Resize(32, 32),\n",
    "        A.Normalize(\n",
    "            mean=tuple(dataset_mean),\n",
    "            std=tuple(dataset_std),\n",
    "            max_pixel_value=255.0,\n",
    "            normalization=\"standard\",\n",
    "            p=1.0),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_resize = A.Compose([\n",
    "        A.Resize(32, 32),\n",
    "        ToTensorV2(p=1.0)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_train = r'Dataset/Train'\n",
    "root_dir_augmented = r'Dataset/Augmented'\n",
    "os.makedirs(root_dir_augmented, exist_ok=True)\n",
    "\n",
    "images_path_list = []\n",
    "labels_path_list = []\n",
    "class_idx = {}\n",
    "augmentation_count = 5\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(root_dir_train)\n",
    "                      if os.path.isdir(os.path.join(root_dir_train, d))])\n",
    "\n",
    "for cls_idx, class_name in enumerate(class_names):\n",
    "    class_idx[cls_idx] = class_name\n",
    "    images_tmp = os.path.join(root_dir_train, class_name, \"*.png\")\n",
    "    images_paths = glob.glob(images_tmp)\n",
    "    \n",
    "    for img_path in images_paths:\n",
    "        images_path_list.append(img_path)\n",
    "        labels_path_list.append(cls_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=len(images_path_list) * augmentation_count, \n",
    "            desc=\"Augmenting Images\", \n",
    "            unit=\"img\", \n",
    "            dynamic_ncols=True)\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(root_dir_augmented, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    if not os.path.exists(class_dir):\n",
    "        raise RuntimeError(f\"Failed to create directory: {class_dir}\")\n",
    "\n",
    "for img_path in images_path_list:\n",
    "    class_name = os.path.basename(os.path.dirname(img_path))\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not read image {img_path}\")\n",
    "        pbar.update(augmentation_count)\n",
    "        continue\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    \n",
    "    for aug_num in range(1, augmentation_count + 1):\n",
    "        transformed = transform_album(image=img)\n",
    "        transformed_img = transformed['image']\n",
    "        \n",
    "        transformed_img = transformed_img.permute(1, 2, 0).numpy()\n",
    "        transformed_img = (transformed_img * np.array(dataset_std) + np.array(dataset_mean))\n",
    "        transformed_img = np.clip(transformed_img * 255, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        new_filename = f\"{base_name}_{aug_num:02d}.png\"\n",
    "        new_path = os.path.join(root_dir_augmented, class_name, new_filename)\n",
    "        \n",
    "        if not os.path.exists(os.path.dirname(new_path)):\n",
    "            os.makedirs(os.path.dirname(new_path), exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            save_success = cv2.imwrite(new_path, cv2.cvtColor(transformed_img, cv2.COLOR_RGB2BGR))\n",
    "            if not save_success:\n",
    "                Image.fromarray(transformed_img).save(new_path)\n",
    "                print(f\"Used PIL fallback for {new_path}\")\n",
    "        except Exception as save_error:\n",
    "            print(f\"Failed to save {new_path}: {str(save_error)}\")\n",
    "            continue\n",
    "        \n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix_str(f\"Processing: {class_name}/{new_filename}\")\n",
    "\n",
    "pbar.close()\n",
    "output_files = glob.glob(os.path.join(root_dir_augmented, \"**\", \"*.png\"), recursive=True)\n",
    "print(f\"\\nAugmentation complete. {len(images_path_list)} â {len(images_path_list)*augmentation_count} files\")\n",
    "print(f\"Augmented images saved in: {os.path.abspath(root_dir_augmented)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_test = r'Dataset/Test'\n",
    "\n",
    "images_path_list = []\n",
    "for class_name in os.listdir(root_dir_test):\n",
    "    class_path = os.path.join(root_dir_test, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images_path_list.extend(glob.glob(os.path.join(class_path, \"*.png\")))\n",
    "\n",
    "pbar = tqdm(total=len(images_path_list), \n",
    "           desc=\"Processing Images\", \n",
    "           unit=\"img\", \n",
    "           dynamic_ncols=True)\n",
    "\n",
    "for img_path in images_path_list:\n",
    "    try:\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        transformed = transform_simple(image=img)\n",
    "        processed_img = transformed['image']\n",
    "        \n",
    "        processed_img = processed_img.permute(1, 2, 0).numpy()\n",
    "        processed_img = (processed_img * dataset_std + dataset_mean) * 255\n",
    "        processed_img = processed_img.clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "        cv2.imwrite(img_path, cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
    "        pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing {img_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\nProcessing complete. {len(images_path_list)} images replaced\")\n",
    "print(f\"Original images overwritten in: {os.path.abspath(root_dir_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir_val = r'Dataset/Val'\n",
    "\n",
    "images_path_list = []\n",
    "for class_name in os.listdir(root_dir_val):\n",
    "    class_path = os.path.join(root_dir_val, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images_path_list.extend(glob.glob(os.path.join(class_path, \"*.png\")))\n",
    "\n",
    "pbar = tqdm(total=len(images_path_list), \n",
    "           desc=\"Processing Images\", \n",
    "           unit=\"img\", \n",
    "           dynamic_ncols=True)\n",
    "\n",
    "for img_path in images_path_list:\n",
    "    try:\n",
    "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        transformed = transform_simple(image=img)\n",
    "        processed_img = transformed['image']\n",
    "        \n",
    "        processed_img = processed_img.permute(1, 2, 0).numpy()\n",
    "        processed_img = (processed_img * dataset_std + dataset_mean) * 255\n",
    "        processed_img = processed_img.clip(0, 255).astype(np.uint8)\n",
    "        \n",
    "        cv2.imwrite(img_path, cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
    "        pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing {img_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\nProcessing complete. {len(images_path_list)} images replaced\")\n",
    "print(f\"Original images overwritten in: {os.path.abspath(root_dir_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDB(Dataset):\n",
    "    def __init__(self, images_path_list, labels_path_list, transform=None):\n",
    "        self.images_path_list = images_path_list\n",
    "        self.labels_path_list = labels_path_list\n",
    "        self.transform = transform\n",
    "        self.class_names = sorted(list(set(os.path.basename(os.path.dirname(p)) for p in images_path_list)))\n",
    "        self.idx_to_class = self._create_label_mapping()\n",
    "        \n",
    "    def _create_label_mapping(self):\n",
    "        return {idx: name for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_path_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.images_path_list[index]\n",
    "        label = self.labels_path_list[index]\n",
    "        \n",
    "        try:\n",
    "            import cv2\n",
    "            image = cv2.imread(path)\n",
    "            if image is None:\n",
    "                raise ValueError(\"Image could not be read\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.transform:\n",
    "                if isinstance(self.transform, A.Compose):\n",
    "                    # Albumentations Pipeline\n",
    "                    augmented = self.transform(image=image)\n",
    "                    image = augmented[\"image\"]\n",
    "                else:\n",
    "                    # PyTorch PIL\n",
    "                    from PIL import Image\n",
    "                    image = Image.open(path).convert(\"RGB\")\n",
    "                    image = self.transform(image)\n",
    "            else:\n",
    "                from albumentations.pytorch import ToTensorV2\n",
    "                image = ToTensorV2()(image=image)[\"image\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {path}: {e}\")\n",
    "            image = torch.zeros(3, 32, 32)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_name(self, label_idx):\n",
    "        return self.idx_to_class.get(label_idx, \"unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignDBNPY(Dataset):\n",
    "    def __init__(self, X_npy_path, y_npy_path, transform=None):\n",
    "        if isinstance(X_npy_path, (str, bytes, os.PathLike)):\n",
    "            self.X = np.load(X_npy_path)\n",
    "        else:\n",
    "            self.X = X_npy_path\n",
    "\n",
    "        if isinstance(y_npy_path, (str, bytes, os.PathLike)):\n",
    "            self.y = np.load(y_npy_path)\n",
    "        else:\n",
    "            self.y = y_npy_path\n",
    "            \n",
    "        self.transform = transform\n",
    "        self.y_int = np.argmax(self.y, axis=1)\n",
    "        \n",
    "        self.class_names = [\n",
    "            'barred_area',\n",
    "            'cross_walk',\n",
    "            'go_straight',\n",
    "            'no_passing_zone_beginning',\n",
    "            'parking_zone',\n",
    "            'priority_over',\n",
    "            'steep_hill_downhill',\n",
    "            'steep_hill_uphill',\n",
    "            'stop',\n",
    "            'tunnel_beginning',\n",
    "            'turn_left',\n",
    "            'turn_right'\n",
    "        ]\n",
    "        self.idx_to_class = self._create_label_mapping()\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        return {idx: name for idx, name in enumerate(class_names)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.X[index]\n",
    "        label = int(self.y_int[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = path.transpose(1, 2, 0)\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        else:\n",
    "            image = torch.from_numpy(path)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_class_name(self, label_idx):\n",
    "        return self.class_names[label_idx] if label_idx < len(self.class_names) else \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test List and NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 32\n",
    "\n",
    "root_dir = r'Dataset'\n",
    "root_dir_train = r'Dataset/Train'\n",
    "root_dir_test = r'Dataset/Test'\n",
    "root_dir_val = r'Dataset/Val'\n",
    "\n",
    "images_path_list_train = []\n",
    "labels_path_list_train = []\n",
    "\n",
    "images_path_list_test = []\n",
    "labels_path_list_test = []\n",
    "\n",
    "images_path_list_val = []\n",
    "labels_path_list_val = []\n",
    "\n",
    "class_idx = {}\n",
    "\n",
    "class_names = sorted([d for d in os.listdir(root_dir_train)\n",
    "                      if os.path.isdir(os.path.join(root_dir_train, d))])\n",
    "\n",
    "for cls_idx, class_name in enumerate(class_names):\n",
    "    class_idx[cls_idx] = class_name\n",
    "    \n",
    "    # Train images (Augmented)\n",
    "    train_pattern = os.path.join(root_dir_train, class_name, \"*.png\")\n",
    "    train_images_paths = glob.glob(train_pattern)\n",
    "    np.random.shuffle(train_images_paths)\n",
    "    for train_path in train_images_paths:\n",
    "        images_path_list_train.append(train_path)\n",
    "        labels_path_list_train.append(cls_idx)\n",
    "\n",
    "    # Test images\n",
    "    test_pattern = os.path.join(root_dir_test, class_name, \"*.png\")\n",
    "    test_images_paths = glob.glob(test_pattern)\n",
    "    np.random.shuffle(test_images_paths)\n",
    "    for test_path in test_images_paths:\n",
    "        images_path_list_test.append(test_path)\n",
    "        labels_path_list_test.append(cls_idx)\n",
    "    \n",
    "    # Validation images\n",
    "    val_pattern = os.path.join(root_dir_val, class_name, \"*.png\")\n",
    "    val_images_paths = glob.glob(val_pattern)\n",
    "    np.random.shuffle(val_images_paths)\n",
    "    for val_path in val_images_paths:\n",
    "        images_path_list_val.append(val_path)\n",
    "        labels_path_list_val.append(cls_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = len(images_path_list_train)\n",
    "total_test = len(images_path_list_test)\n",
    "total_val = len(images_path_list_val)\n",
    "total_all = total_train + total_test\n",
    "\n",
    "perc_train = total_train / total_all * 100\n",
    "perc_test = total_test / total_all * 100\n",
    "\n",
    "print(\"Final dataset sizes:\")\n",
    "print(f\"Training: {total_train} samples ({perc_train:.2f}%)\")\n",
    "print(f\"Testing: {total_test} samples ({perc_test:.2f}%)\")\n",
    "print(f\"Validation: {total_val} samples\")\n",
    "\n",
    "train_counts = Counter(labels_path_list_train)\n",
    "test_counts = Counter(labels_path_list_test)\n",
    "val_counts = Counter(labels_path_list_val)\n",
    "\n",
    "print(\"\\nTraining Class Distribution:\")\n",
    "for idx in sorted(train_counts.keys()):\n",
    "    print(f\"Class '{class_idx[idx]}' (Index {idx}): {train_counts[idx]} samples\")\n",
    "\n",
    "print(\"\\nTesting Class Distribution:\")\n",
    "for idx in sorted(test_counts.keys()):\n",
    "    print(f\"Class '{class_idx[idx]}' (Index {idx}): {test_counts[idx]} samples\")\n",
    "\n",
    "print(\"\\nValidation Class Distribution:\")\n",
    "for idx in sorted(val_counts.keys()):\n",
    "    print(f\"Class '{class_idx[idx]}' (Index {idx}): {val_counts[idx]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('images_path_list_train' in globals() and \n",
    "    'images_path_list_test' in globals() and \n",
    "    'images_path_list_val' in globals()):\n",
    "    \n",
    "    train_files = set(images_path_list_train)\n",
    "    test_files = set(images_path_list_test)\n",
    "    val_files = set(images_path_list_val)\n",
    "    \n",
    "    dup_train_val = train_files.intersection(val_files)\n",
    "    dup_train_test = train_files.intersection(test_files)\n",
    "    dup_val_test = val_files.intersection(test_files)\n",
    "    \n",
    "    print(\"Duplicates between training and validation:\", len(dup_train_val))\n",
    "    print(\"Duplicates between training and test:\", len(dup_train_test))\n",
    "    print(\"Duplicates between validation and test:\", len(dup_val_test))\n",
    "else:\n",
    "    print(\"File path lists not found; skipping duplicate check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(labels, num_classes):\n",
    "    encoded = np.zeros((len(labels), num_classes), dtype=np.float32)\n",
    "    encoded[np.arange(len(labels)), labels] = 1.0\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img_npy(image_paths, labels, save_dir, dataset_type, mean, std):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    mean_arr = np.array(mean, dtype=np.float32)\n",
    "    std_arr = np.array(std, dtype=np.float32)\n",
    "    \n",
    "    for img_path, label in tqdm(zip(image_paths, labels), \n",
    "                              total=len(image_paths), \n",
    "                              desc=f\"Processing {save_dir}\"):\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"Skipping unreadable file: {img_path}\")\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.resize(img, (img_size, img_size))\n",
    "            \n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = (img - mean_arr) / std_arr\n",
    "            \n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "            \n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupted file {img_path}: {e}\")\n",
    "    \n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = one_hot_encoder(np.array(y, dtype=np.int64), num_classes=len(class_names))\n",
    "    \n",
    "    np.save(os.path.join(save_dir, f'X_{dataset_type}_data.npy'), X)\n",
    "    np.save(os.path.join(save_dir, f'y_{dataset_type}_labels.npy'), y)\n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\") \n",
    "    print(f\"\\nSaved {X.shape[0]} samples to {save_dir}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_img_npy(images_path_list_train,\n",
    "                labels_path_list_train, \n",
    "               root_dir,\n",
    "               'train',\n",
    "               mean=dataset_mean,\n",
    "               std=dataset_std)\n",
    "\n",
    "process_img_npy(images_path_list_test,\n",
    "                labels_path_list_test,\n",
    "               root_dir,\n",
    "               'test',\n",
    "               mean=dataset_mean,\n",
    "               std=dataset_std)\n",
    "\n",
    "process_img_npy(images_path_list_val,\n",
    "                labels_path_list_val,\n",
    "               root_dir,\n",
    "               'val',\n",
    "               mean=dataset_mean,\n",
    "               std=dataset_std)\n",
    "\n",
    "print(\"\\nDataset preprocessing complete!\")\n",
    "print(f\"Final dataset sizes:\")\n",
    "print(f\"- Training: {len(images_path_list_train)} samples\")\n",
    "print(f\"- Testing: {len(images_path_list_test)} samples\")\n",
    "print(f\"- Validation: {len(images_path_list_val)} samples\")\n",
    "print(f\"One-hot encoded labels shape: ({len(class_names)} classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_data(save_dir, type):\n",
    "    X = np.load(os.path.join(save_dir, f'X_{type}_data.npy'))\n",
    "    y = np.load(os.path.join(save_dir, f'y_{type}_labels.npy'))\n",
    "    return X, y\n",
    "\n",
    "X_train_npy, y_train_npy = load_npy_data(root_dir, 'train')\n",
    "X_test_npy, y_test_npy = load_npy_data(root_dir, 'test')\n",
    "X_val_npy, y_val_npy = load_npy_data(root_dir, 'val')\n",
    "\n",
    "print(\"\\nVerifying NPY file contents:\")\n",
    "print(f\"\\nTraining data shape: {X_train_npy.shape}\")\n",
    "print(f\"Training labels shape: {y_train_npy.shape}\")\n",
    "print(f\"\\nTest data shape: {X_test_npy.shape}\")\n",
    "print(f\"Test labels shape: {y_test_npy.shape}\")\n",
    "print(f\"\\nValidation data shape: {X_val_npy.shape}\")\n",
    "print(f\"Validation labels shape: {y_val_npy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(image_tensor, mean, std):\n",
    "    image = image_tensor.cpu().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    image = image * std + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image\n",
    "\n",
    "def verify_dataset(dataset, class_names, data_dir=None, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
    "    counts = Counter(dataset.y_int)\n",
    "    class_labels = sorted(counts.keys())\n",
    "    class_counts = [counts[cls] for cls in class_labels]\n",
    "    \n",
    "    print(\"\\nClass Distribution Details:\")\n",
    "    for cls_idx in sorted(counts.keys()):\n",
    "        print(f\"{class_names[cls_idx]} (Index {cls_idx}): {counts[cls_idx]} samples\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.barplot(\n",
    "        x=class_labels, \n",
    "        y=class_counts, \n",
    "        hue=class_labels,\n",
    "        palette=\"viridis\",\n",
    "        legend=False\n",
    "    )\n",
    "    plt.title(\"Class Distribution\")\n",
    "    plt.xlabel(\"Class Index\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    print(\"\\nClass Distribution Summary:\")\n",
    "    print(f\"Total samples: {len(dataset)}\")\n",
    "    print(f\"Number of classes: {len(class_names)}\")\n",
    "    print(f\"Mean samples per class: {np.mean(class_counts):.1f}\")\n",
    "    print(f\"Std samples per class: {np.std(class_counts):.1f}\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    sample_idx = random.randint(0, len(dataset)-1)\n",
    "    img, label = dataset[sample_idx]\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img_disp = denormalize_image(img, mean, std)\n",
    "    else:\n",
    "        img_disp = img.transpose(1, 2, 0)\n",
    "    plt.imshow(img_disp)\n",
    "    plt.title(f\"Random Sample\\nClass: {class_names[label]} (Idx: {label})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    plot_one_per_class(dataset, class_names, mean, std)\n",
    "    \n",
    "    if data_dir:\n",
    "        plot_directory_samples(data_dir, class_names)\n",
    "\n",
    "def plot_one_per_class(dataset, class_names, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)):\n",
    "    class_to_indices = {i: [] for i in range(len(class_names))}\n",
    "    for idx, label in enumerate(dataset.y_int):\n",
    "        class_to_indices[label].append(idx)\n",
    "    \n",
    "    chosen_indices = []\n",
    "    for cls in sorted(class_to_indices.keys()):\n",
    "        if class_to_indices[cls]:\n",
    "            chosen_indices.append(random.choice(class_to_indices[cls]))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    cols = 6\n",
    "    rows = (len(chosen_indices) + cols - 1) // cols\n",
    "    \n",
    "    for i, idx in enumerate(chosen_indices):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        img, label = dataset[idx]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_disp = denormalize_image(img, mean, std)\n",
    "        else:\n",
    "            img_disp = img.transpose(1, 2, 0)\n",
    "            img_disp = np.clip(img_disp, 0, 1)\n",
    "        plt.imshow(img_disp)\n",
    "        plt.title(f\"{class_names[label]}\\n(Idx: {label})\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"One Random Sample per Class from Dataset\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_directory_samples(data_dir, class_names):\n",
    "    train_dir = os.path.join(data_dir, 'Train')\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    cols = 6\n",
    "    rows = (len(class_names) + cols - 1) // cols\n",
    "    for cls_idx, class_name in enumerate(class_names):\n",
    "        plt.subplot(rows, cols, cls_idx+1)\n",
    "        class_dir = os.path.join(train_dir, str(cls_idx))\n",
    "        if os.path.exists(class_dir):\n",
    "            images = [f for f in os.listdir(class_dir) if f.endswith('.png')]\n",
    "            if images:\n",
    "                img_path = os.path.join(class_dir, random.choice(images))\n",
    "                img = plt.imread(img_path)\n",
    "                plt.imshow(img)\n",
    "        plt.title(f\"{class_name}\\n(Idx: {cls_idx})\", fontsize=8)\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(\"Sample Images from Directory Structure\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrafficSignDBNPY(\n",
    "    X_npy_path=r'Dataset/X_train_data.npy',\n",
    "    y_npy_path=r'Dataset/y_train_labels.npy',\n",
    "    transform=transform_resize\n",
    ")\n",
    "\n",
    "test_dataset = TrafficSignDBNPY(\n",
    "    X_npy_path=r'Dataset/X_test_data.npy',\n",
    "    y_npy_path=r'Dataset/y_test_labels.npy',\n",
    "    transform=transform_resize\n",
    ")\n",
    "\n",
    "val_dataset = TrafficSignDBNPY(\n",
    "    X_npy_path=r'Dataset/X_val_data.npy',\n",
    "    y_npy_path=r'Dataset/y_val_labels.npy',\n",
    "    transform=transform_resize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dataset(train_dataset, class_names, mean=dataset_mean, std=dataset_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dataset(test_dataset, class_names, mean=dataset_mean, std=dataset_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_dataset(val_dataset, class_names, mean=dataset_mean, std=dataset_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, accuracy_score,\n",
    "                             classification_report, confusion_matrix)\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'Dataset'\n",
    "root_dir_model = r'TrainedModels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(root_dir, 'X_train_data.npy'))\n",
    "y_train = np.load(os.path.join(root_dir, 'y_train_labels.npy'))\n",
    "\n",
    "X_test  = np.load(os.path.join(root_dir, 'X_test_data.npy'))\n",
    "y_test  = np.load(os.path.join(root_dir, 'y_test_labels.npy'))\n",
    "\n",
    "X_val  = np.load(os.path.join(root_dir, 'X_val_data.npy'))\n",
    "y_val  = np.load(os.path.join(root_dir, 'y_val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_test  = np.argmax(y_test, axis=1)\n",
    "y_val  = np.argmax(y_val, axis=1)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "X_test  = torch.from_numpy(X_test).float()\n",
    "y_test  = torch.from_numpy(y_test).long()\n",
    "\n",
    "X_val  = torch.from_numpy(X_val).float()\n",
    "y_val  = torch.from_numpy(y_val).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_Tensor = TensorDataset(X_train, y_train)\n",
    "test_dataset_Tensor = TensorDataset(X_test, y_test)\n",
    "val_dataset_Tensor = TensorDataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset_Tensor,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    "    )\n",
    "\n",
    "test_loader  = DataLoader(\n",
    "    dataset=test_dataset_Tensor,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    "    )\n",
    "\n",
    "val_loader  = DataLoader(\n",
    "    dataset=val_dataset_Tensor,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignCNN(nn.Module):\n",
    "    def __init__(self, num_classes=12):\n",
    "        super(TrafficSignCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.flatten_dim = 64 * 8 * 8\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 256)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "        logics = self.fc2(x)\n",
    "        # F.softmax(logics, dim=1)\n",
    "        \n",
    "        return logics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = TrafficSignCNN(num_classes=12).to(device)\n",
    "summary(model, input_size=(3, 32, 32))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max',factor=0.1, patience=5, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 32\n",
    "best_acc = 0.0\n",
    "\n",
    "history = {'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}\n",
    "print(\"Training the model...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\")\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    val_loss, val_acc = evaluate_model(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_acc)\n",
    "    \n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['accuracy'].append(epoch_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_acc)\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Current learning rate: {param_group['lr']}\")\n",
    "    \n",
    "    if (val_acc >= best_acc):\n",
    "        best_acc = val_acc\n",
    "        model_save_path = os.path.join(root_dir_model, 'traffic_sign_cnn_V06.pth')\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"Best model updated and saved with val_accuracy = {val_acc:.4f}\")\n",
    "        print(f\"Current val_acc = {val_acc:.4f}, Best val_acc = {best_acc:.4f}\")\n",
    "    else:\n",
    "        print(f\"Model not improved. Best val_accuracy remains at {best_acc:.4f}\")\n",
    "    \n",
    "    epoch_duration = time.time() - epoch_start\n",
    "    remaining_time = (epochs - epoch - 1) * epoch_duration\n",
    "    print(f\"Epoch {epoch+1}/{epochs}: loss={epoch_loss:.4f}, accuracy={epoch_acc:.4f}, \"\n",
    "          f\"val_loss={val_loss:.4f}, val_accuracy={val_acc:.4f}\")\n",
    "    print(f\"Epoch time: {epoch_duration:.2f}s, estimated remaining: {remaining_time:.2f}s\\n\")\n",
    "    \n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nExporting model to ONNX format...\")\n",
    "try:\n",
    "    example_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    model.eval()\n",
    "    torch.onnx.export(\n",
    "        model, \n",
    "        (example_input,), \n",
    "        os.path.join(root_dir_model, 'traffic_sign_cnn_V06.onnx'),\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "        opset_version=13,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(\"Successfully exported ONNX model to:\", os.path.join(root_dir_model, 'traffic_sign_cnn_V06.onnx'))\n",
    "except Exception as e:\n",
    "    print(f\"Error exporting ONNX model: {e}\")\n",
    "\n",
    "model_save_path = os.path.join(root_dir_model, 'traffic_sign_cnn_V06_F.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(\"Saved PyTorch model to:\", model_save_path)\n",
    "\n",
    "history_df = pd.DataFrame(history)\n",
    "history_save_path = os.path.join(root_dir_model, 'historyV06.csv')\n",
    "history_df.to_csv(history_save_path, index=False)\n",
    "print(\"Saved training history to:\", history_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'Dataset'\n",
    "root_dir_model = r'TrainedModels'\n",
    "batch_size = 64\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "print(\"----------- Starting Model Evaluation -----------\")\n",
    "print(\"Loading preprocessed test data...\")\n",
    "\n",
    "X_test = np.load(os.path.join(root_dir, 'X_test_data.npy'))\n",
    "y_test = np.load(os.path.join(root_dir, 'y_test_labels.npy'))\n",
    "\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Loading model...\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TrafficSignCNN(num_classes=12).to(device)\n",
    "model_path = os.path.join(root_dir_model, 'traffic_sign_cnn_V06.pth')\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Evaluating model on test data...\")\n",
    "test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "history_path = os.path.join(root_dir_model, 'historyV06.csv')\n",
    "if os.path.exists(history_path):\n",
    "    print(\"Loading training history...\")\n",
    "    history_df = pd.read_csv(history_path)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_df['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_df['loss'], label='Train Loss')\n",
    "    plt.plot(history_df['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"----------- Model Evaluation Complete -----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(model, image):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image.unsqueeze(0).to(device))\n",
    "        prob = F.softmax(output, dim=1)\n",
    "        pred = torch.argmax(prob, dim=1).item()\n",
    "    return pred, prob.cpu().numpy()\n",
    "\n",
    "print(\"\\nSample validation predictions:\")\n",
    "num_samples = 10\n",
    "indices = np.random.choice(len(val_dataset_Tensor), num_samples, replace=False)\n",
    "for idx in indices:\n",
    "    img, label = val_dataset_Tensor[idx]\n",
    "    pred, prob = predict_sample(model, img)\n",
    "    print(f\"Sample index {idx}: Ground truth: {label.item()}, Prediction: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_image(image_tensor, mean, std):\n",
    "    image = image_tensor.cpu().numpy().transpose(1, 2, 0)\n",
    "    mean = np.array(mean)\n",
    "    std = np.array(std)\n",
    "    image = image * std + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    return image\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i, idx in enumerate(np.random.choice(len(val_dataset_Tensor), 10, replace=False)):\n",
    "    img, label = val_dataset_Tensor[idx]\n",
    "    pred, _ = predict_sample(model, img)\n",
    "    img_disp = denormalize_image(img, dataset_mean, dataset_std)\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(img_disp)\n",
    "    plt.title(f\"GT: {label.item()}, Pred: {pred}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Validation Samples: Ground Truth vs. Prediction\", fontsize=16)\n",
    "plt.tight_layout(rect=(0, 0.03, 1, 0.95))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = os.path.join(r'TrainedModels', 'traffic_sign_cnn_V06_F.pth')\n",
    "model = TrafficSignCNN(num_classes=12).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_full(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)  # raw logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    top3_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # Get top 3 predictions\n",
    "            topk_values, topk_preds = torch.topk(outputs, 3, dim=1)\n",
    "            # Compare if true label is among top 3\n",
    "            for i in range(labels.size(0)):\n",
    "                if labels[i] in topk_preds[i]:\n",
    "                    top3_correct += 1\n",
    "    top3_accuracy = top3_correct / total\n",
    "\n",
    "    return avg_loss, accuracy, all_preds, all_labels, top3_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc, preds, true_labels, top3_acc = evaluate_model_full(model, test_loader, device)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Test Top-3 Accuracy: {top3_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, preds, target_names=[f\"Class {i}\" for i in range(12)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc, val_preds, val_true_labels, val_top3_acc = evaluate_model_full(model, val_loader, device)\n",
    "\n",
    "print(f\"\\nValidation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n",
    "print(f\"Validation Top-3 Accuracy: {val_top3_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_val = confusion_matrix(val_true_labels, val_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_val, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[f\"Class {i}\" for i in range(12)],\n",
    "            yticklabels=[f\"Class {i}\" for i in range(12)])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Validation Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValidation Classification Report:\")\n",
    "print(classification_report(val_true_labels, val_preds, target_names=[f\"Class {i}\" for i in range(12)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
